{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import openai\n",
    "OPENAI_API_KEY = ''\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "\n",
    "def ndesc_generator(grammar_pattern, gp_desc, group, g_desc, group_mm, examples):\n",
    "    # openai.ChatCompletion.create\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "                {'role':'system', 'content':'You serve as a professional English teacher.'}, \n",
    "                {'role':'user', 'content':f\"\"\"In grammar pattern \"{grammar_pattern}\", {gp_desc} \n",
    "                                            Nouns exhibiting this pattern can be categorized into semantic groups.\n",
    "                                            In '{group}': {g_desc}\"\"\"}, \n",
    "                {'role':'assistant', 'content':f\"\"\"{GROUP_MM} belobg to '{group}'.\n",
    "                and here are some example sentences: {examples}\"\"\"}, \n",
    "                {\"role\": \"user\",\n",
    "                \"content\": f\"\"\"The noun group in {grammar_pattern} of '{group}' indicates [MASK].\"\"\"}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1500,\n",
    "    )\n",
    "    # generalize, induce\n",
    "    response_text = response.choices[0].message.content\n",
    "    return response_text\n",
    "\n",
    "def extract_partial_sentence(text):\n",
    "    pattern = r'indicates(.*)'\n",
    "    match = re.search(pattern, text)\n",
    "\n",
    "    if match:\n",
    "        partial_sentence = match.group(1).strip()\n",
    "        return partial_sentence\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def subject_extractor(n_desc):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Task: Extract the subject of sentence.\n",
    "                example:\n",
    "                Q: someone sympathizes with someone else.\n",
    "                A: someone\n",
    "                Q: {n_desc}\n",
    "                A: [MASK]\n",
    "                \"\"\"\n",
    "            },\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1500,\n",
    "    )\n",
    "    # generalize, induce\n",
    "    subject = response.choices[0].message.content\n",
    "    return subject\n",
    "\n",
    "\n",
    "\n",
    "NDESC = ndesc_generator(PATTERN, GP_DESC, GROUP, G_DESC, GROUP_MM, EXAMPLE)\n",
    "_ = extract_partial_sentence(NDESC)\n",
    "SC = subject_extractor(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import *\n",
    "import transformers as ppb\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from spacy import displacy\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, silhouette_score\n",
    "\n",
    "\n",
    "## Elbow Plot\n",
    "def plot_elbow_method(embedding):\n",
    "  Sum_of_squared_distances = []\n",
    "  K = range(1,6) #1-5\n",
    "  for k in K:\n",
    "      km = KMeans(n_clusters=k)\n",
    "      km = km.fit(embedding)\n",
    "      labels = km.labels_\n",
    "      print(labels)\n",
    "      Sum_of_squared_distances.append(km.inertia_)\n",
    "  plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "  plt.xlabel('k')\n",
    "  plt.ylabel('Sum_of_squared_distances')\n",
    "  plt.title('Elbow Method For Optimal k')\n",
    "  plt.show()\n",
    "\n",
    "## Scatter Plot-2D\n",
    "def plot_graph(clusters, umap_data):\n",
    "  result = pd.DataFrame(umap_data, columns=['x', 'y'])\n",
    "  result['labels'] = clusters\n",
    "  plt.figure(figsize=(10,10))\n",
    "  sns.scatterplot(\n",
    "      x=\"x\", y=\"y\",\n",
    "      hue=\"labels\",\n",
    "      palette='Spectral',\n",
    "      data=result,\n",
    "      legend=\"full\")\n",
    "\n",
    "## PCA and Kmeans\n",
    "def get_cluster_kmeans(vectorize, num_clusters, r_state=100):\n",
    "  km = KMeans(n_clusters = num_clusters, random_state=r_state )\n",
    "  km.fit(vectorize)\n",
    "  cluster_list = km.labels_.tolist()\n",
    "  return cluster_list\n",
    "\n",
    "def pca_reduction(similarity_matrix, n_components):\n",
    "  one_min_sim = 1 - similarity_matrix\n",
    "  pca = PCA(n_components=10)\n",
    "  pos = pca.fit_transform(one_min_sim)\n",
    "  x_pos, y_pos = pos[:, 0], pos[:, 1]\n",
    "  return (x_pos, y_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# sample test\n",
    "labels = [\"topic\", \"subject\", \"clothes\", \"attire\", \"taste\", \"smell\", \"sound\"]\n",
    "embedder = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "corpus_embeddings = embedder.encode(labels)\n",
    "\n",
    "# (Optional) Normalize the embeddings to unit length\n",
    "normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def plot_elbow_method(embedding):\n",
    "\n",
    "  Sum_of_squared_distances = []\n",
    "  K = range(60, 75) #1-5\n",
    "  for k in K:\n",
    "      km = KMeans(n_clusters=k)\n",
    "      km = km.fit(embedding)\n",
    "\n",
    "\n",
    "      label_to_tags = {}\n",
    "      # Iterate over labels and corresponding tags\n",
    "      for label, tag in zip(km.labels_, labels):\n",
    "          if label not in label_to_tags:\n",
    "              label_to_tags[label] = []\n",
    "          label_to_tags[label].append(tag)\n",
    "\n",
    "      # Print the mapping\n",
    "      for label, tag_list in sorted(label_to_tags.items()):\n",
    "          print(f\"{label}: {', '.join(tag_list)}\")\n",
    "\n",
    "      Sum_of_squared_distances.append(km.inertia_)\n",
    "  plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "  plt.xlabel('k')\n",
    "  plt.ylabel('Sum_of_squared_distances')\n",
    "  plt.title('Elbow Method For Optimal k')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "plot_elbow_method(corpus_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
