{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "555a3bd8",
   "metadata": {},
   "source": [
    "### Adj (xml to json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae1959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "with open('src/COBUILD.grammar.pattern.na.xml', 'r', encoding = 'utf-8') as f:\n",
    "    conts = f.readlines()\n",
    "    bs_conts = []\n",
    "    for line in conts:\n",
    "        bs_conts.append(bs(line, 'xml'))\n",
    "\n",
    "        \n",
    "json_dict = {}\n",
    "for bs_cont in bs_conts:\n",
    "    for entry in tqdm(bs_cont.find_all('pattern')):\n",
    "        if int(entry.get('number')) >= 76:\n",
    "            _dict = {}\n",
    "            # Grammar pattern\n",
    "            if entry.find('title') != None:\n",
    "                GP = entry.find('title').get_text()\n",
    "                tokens = word_tokenize(GP)\n",
    "                for token in tokens:\n",
    "                    if token == 'n' or token == 'pl-n' or token == 'n/-ing':\n",
    "                        # Adjective desc\n",
    "                        if entry.find('intro') != None:\n",
    "                            _dict['Desc'] = entry.find('p').get_text()\n",
    "                        # W/ Groups \n",
    "                        if entry.find('group') != None:\n",
    "                            if entry.find('group').get('type') != None:\n",
    "                                group_list = []\n",
    "                                for group in entry.find_all('group'):\n",
    "                                    # Group title\n",
    "                                    if group.find('title') != None:\n",
    "                                        group_dict = {}\n",
    "                                        group_dict['Group'] = group.find('title').get_text()\n",
    "                                        # Group desc\n",
    "                                        if group.find('desc') != None:\n",
    "                                            group_dict['G_Desc'] = group.find('desc').get_text()\n",
    "                                        # Examples\n",
    "                                        if group.find('exmplblk') != None:\n",
    "                                            for exmplblk in group.find_all('exmplblk'):\n",
    "                                                if exmplblk.find('exmpl') != None:\n",
    "                                                    exmpl_list = []\n",
    "                                                    for exmpl in exmplblk.find_all('exmpl'):\n",
    "                                                        exmpl_list.append(exmpl.get_text())\n",
    "                                            group_dict['Examples'] = exmpl_list   \n",
    "                                        group_list.append(group_dict)\n",
    "                                        # Group members\n",
    "                                        if group.find('lemma') != None:\n",
    "                                            member_list = []\n",
    "                                            for lemma in group.find_all('lemma'):\n",
    "                                                member_list.append(lemma.get_text())\n",
    "                                            group_dict['Members'] = member_list\n",
    "                                _dict['Groups'] = group_list   \n",
    "                            # W/O Groups\n",
    "                            else:\n",
    "                                # Examples\n",
    "                                if entry.find('exmplblk') != None:\n",
    "                                    exmplblk_list = []\n",
    "                                    for exmplblk in entry.find_all('exmplblk'):\n",
    "                                        if exmplblk.find('exmpl') != None:\n",
    "                                            exmpl_list = []\n",
    "                                            for exmpl in exmplblk.find_all('exmpl'):\n",
    "                                                #print(exmpl.get_text())\n",
    "                                                exmpl_list.append(exmpl.get_text())\n",
    "                                        \n",
    "                                        #exmplblk_list = exmplblk.select('exmpl')\n",
    "                                    _dict['Examples'] = exmpl_list   \n",
    "                                # Members\n",
    "                                if entry.find('lemma') != None:\n",
    "                                    member_list = []\n",
    "                                    for lemma in entry.find_all('lemma'):\n",
    "                                        member_list.append(lemma.get_text().strip())\n",
    "                                    _dict['Members'] = member_list\n",
    "                        # Store\n",
    "                        json_dict[GP] = _dict\n",
    "\n",
    "\n",
    "\n",
    "#json_dict\n",
    "with open ('result/adjectives.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_dict, f, indent = 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f96623af",
   "metadata": {},
   "source": [
    "### Noun (xml to json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "with open('src/COBUILD.grammar.pattern.na.xml', 'r', encoding = 'utf-8') as f:\n",
    "    conts = f.readlines()\n",
    "    bs_conts = []\n",
    "    for line in conts:\n",
    "        bs_conts.append(bs(line, 'xml'))\n",
    "\n",
    "        \n",
    "json_dict = {}\n",
    "for bs_cont in bs_conts:\n",
    "    for entry in tqdm(bs_cont.find_all('pattern')):\n",
    "        if int(entry.get('number'))<76: \n",
    "            _dict = {}\n",
    "            # Grammar pattern\n",
    "            if entry.find('title') != None:\n",
    "                GP = entry.find('title').get_text()\n",
    "                tokens = word_tokenize(GP)\n",
    "                for token in tokens:\n",
    "                    if token == 'n' or token == 'pl-n' or token == 'n/-ing': #if token == 'N':\n",
    "                        # Noun desc\n",
    "                        if entry.find('intro') != None:\n",
    "                            _dict['Desc'] = entry.find('p').get_text()\n",
    "                        # W/ Groups \n",
    "                        if entry.find('group') != None:\n",
    "                            if entry.find('group').get('type') != None:\n",
    "                                group_list = []\n",
    "                                for group in entry.find_all('group'):\n",
    "                                    # Group title\n",
    "                                    if group.find('title') != None:\n",
    "                                        group_dict = {}\n",
    "                                        group_dict['Group'] = group.find('title').get_text()\n",
    "                                        # Group desc\n",
    "                                        if group.find('desc') != None:\n",
    "                                            group_dict['G_Desc'] = group.find('desc').get_text()\n",
    "                                        # Examples\n",
    "                                        if group.find('exmplblk') != None:\n",
    "                                            for exmplblk in group.find_all('exmplblk'):\n",
    "                                                if exmplblk.find('exmpl') != None:\n",
    "                                                    exmpl_list = []\n",
    "                                                    for exmpl in exmplblk.find_all('exmpl'):\n",
    "                                                        exmpl_list.append(exmpl.get_text())\n",
    "                                            group_dict['Examples'] = exmpl_list   \n",
    "                                        group_list.append(group_dict)\n",
    "                                        # Group members\n",
    "                                        if group.find('lemma') != None:\n",
    "                                            member_list = []\n",
    "                                            for lemma in group.find_all('lemma'):\n",
    "                                                member_list.append(lemma.get_text())\n",
    "                                            group_dict['Members'] = member_list\n",
    "                                _dict['Groups'] = group_list   \n",
    "                            # W/O Groups\n",
    "                            else:\n",
    "                                # Examples\n",
    "                                if entry.find('exmplblk') != None:\n",
    "                                    exmplblk_list = []\n",
    "                                    for exmplblk in entry.find_all('exmplblk'):\n",
    "                                        if exmplblk.find('exmpl') != None:\n",
    "                                            exmpl_list = []\n",
    "                                            for exmpl in exmplblk.find_all('exmpl'):\n",
    "                                                #print(exmpl.get_text())\n",
    "                                                exmpl_list.append(exmpl.get_text())\n",
    "                                        \n",
    "                                        #exmplblk_list = exmplblk.select('exmpl')\n",
    "                                    _dict['Examples'] = exmpl_list   \n",
    "                                # Members\n",
    "                                if entry.find('lemma') != None:\n",
    "                                    member_list = []\n",
    "                                    for lemma in entry.find_all('lemma'):\n",
    "                                        member_list.append(lemma.get_text().strip())\n",
    "                                    _dict['Members'] = member_list\n",
    "                        # Store\n",
    "                        json_dict[GP] = _dict\n",
    "\n",
    "\n",
    "\n",
    "#json_dict\n",
    "with open ('result/nouns.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_dict, f, indent = 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "677e69f8-4fb9-48b1-9bc7-a760a3dd0a24",
   "metadata": {},
   "source": [
    "### VERB (chapter 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16432b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "url = f\"https://arts-ccr-002.cal.bham.ac.uk/ch02.html\"\n",
    "response = requests.get(url) #response = requests.get(\"https://arts-ccr-002.cal.bham.ac.uk/ch01.html\")\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "pattern = r'\\bThe\\b.*group'\n",
    "GP_dict = {}\n",
    "G_dict = {}\n",
    "\n",
    "\n",
    "## grammar pattern\n",
    "for hd1 in soup.find_all(\"div\", class_=\"hd1\"):\n",
    "    gp = ''.join(filter(lambda x: not x.isdigit(), hd1.get_text())).strip()\n",
    "    print(gp)\n",
    "    tokens = word_tokenize(gp)\n",
    "    for token in tokens:\n",
    "        if token == 'n' or token == 'pl-n' or token == 'n/-ing':\n",
    "            GP_dict[gp] = {}\n",
    "            \n",
    "            ## grammar desc\n",
    "            st = hd1.find_next_sibling('div', class_='st')\n",
    "            print(st.get_text(strip=True))\n",
    "            GP_dict[gp]['Desc'] = st.get_text(strip=True)\n",
    "            \n",
    "            ## Extract table content\n",
    "            table = st.find_next_sibling('table', class_='mgl')\n",
    "            if table:\n",
    "                table_content = []\n",
    "                rows = table.find_all('tr')\n",
    "                for row in rows:\n",
    "                    cells = row.find_all('td')\n",
    "                    for cell in cells:\n",
    "                        cleaned_cell = re.findall(pattern, cell.get_text().replace(\"`\", \"'\"))\n",
    "                        if cleaned_cell:\n",
    "                            table_content.append(cleaned_cell[0])\n",
    "                            G_dict[cleaned_cell[0]] = {}\n",
    "                print(table_content)\n",
    "                GP_dict[gp]['tmp_g'] = table_content\n",
    "                GP_dict[gp]['Groups'] = []\n",
    "\n",
    "\n",
    "# Find the div with class \"hd5\"\n",
    "for group in soup.find_all(\"div\", class_=\"hd5\"):\n",
    "    g_name1 = ''.join(filter(lambda x: not x.isdigit(), group.get_text().replace(\"`\", \"'\"))).strip()\n",
    "    g_name = re.findall(pattern, group.get_text().replace(\"`\", \"'\"))\n",
    "    if g_name: #'Verbs with other meanings'\n",
    "        g_name = g_name[0]\n",
    "        print(g_name)\n",
    "        if g_name in G_dict.keys():\n",
    "            G_dict[g_name]['Group'] = g_name\n",
    "\n",
    "            # Get the next sibling which is the paragraph containing the desired content\n",
    "            g_desc = group.find_next_sibling('p').get_text(strip=True)\n",
    "            print(g_desc)\n",
    "            G_dict[g_name]['G_Desc'] = g_desc\n",
    "\n",
    "\n",
    "            examples = group.find_next_sibling('ul', class_='example').find_all('li')\n",
    "            g_examples = []\n",
    "            g_members = []\n",
    "\n",
    "            # Extract and store the content within <span class=\"underline\"> in the list\n",
    "            for example in examples:\n",
    "                print(example.get_text())\n",
    "                g_examples.append(example.get_text())\n",
    "                underline_spans = example.find_all('span', class_='underline')\n",
    "                if underline_spans:\n",
    "                    for underline_span in underline_spans:\n",
    "                        g_members.append(underline_span.get_text(strip=True))\n",
    "\n",
    "            # Print the list of content within <span class=\"underline\">\n",
    "            print(g_members)\n",
    "            G_dict[g_name]['Examples'] = g_examples\n",
    "            G_dict[g_name]['Members'] = g_members\n",
    "\n",
    "\n",
    "# Merge\n",
    "for gp, gp_data in GP_dict.items():\n",
    "    if 'tmp_g' in gp_data.keys():\n",
    "        for group in gp_data['tmp_g']:\n",
    "            GP_dict[gp]['Groups'].append(G_dict[group])\n",
    "\n",
    "\n",
    "path = f\"result/verbs_ch02.json\"\n",
    "# Store data\n",
    "with open (path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(GP_dict, f, indent = 4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
