{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d74ee8f-2dd4-408d-a2df-1c47230a08ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29137d97-d3a0-46af-900e-e97c708d0cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import re\n",
    "import transformers\n",
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d66f5-fa07-4009-81c2-299e8ca3d5b1",
   "metadata": {},
   "source": [
    "### 處理data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe1104d4-d59a-4b75-94be-357f62a9b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prepare_data/pattern4.json', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b54c3c57-186d-4412-8fd6-a7fac42d6c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_data = {}\n",
    "verb_data = {}\n",
    "for i in data:\n",
    "    data_list = []\n",
    "    verb_list = []\n",
    "    for j in data[i]:\n",
    "        text = j['example'].replace('<span class=\"x\">','').replace('<span class=\"cl\">','').replace('</span>','').strip()\n",
    "        new_text = ''\n",
    "        test = 0\n",
    "        for k in text.split(' '):\n",
    "            new_text += ' '\n",
    "            new_text += k\n",
    "            if i == k:\n",
    "                test += 1\n",
    "                break\n",
    "        if test != 0:\n",
    "            data_list.append({'pattern': j['pattern'], 'text': new_text.strip()})\n",
    "        if test == 0:\n",
    "            verb_list.append({'pattern': j['pattern'], 'text': new_text.strip()})\n",
    "    if data_list != []:\n",
    "        new_data[i] = data_list\n",
    "    if verb_list != []:\n",
    "        verb_data[i] = verb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa01ea44-1265-49cd-8aeb-1835f829b7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'pattern': 'abandon something', 'text': 'Snow forced many drivers to abandon'}, {'pattern': 'abandon something', 'text': 'Snow forced many drivers to abandon'}, {'pattern': 'abandon something to somebody/something', 'text': 'They had to abandon'}]\n",
      "[{'pattern': 'abandon somebody', 'text': 'The baby had been abandoned by its mother.'}, {'pattern': 'abandon somebody', 'text': 'The baby had been abandoned by its mother.'}, {'pattern': 'abandon somebody to something', 'text': '‘We have been abandoned to our fate,’ said one resident.'}, {'pattern': 'abandon something', 'text': 'They abandoned the match because of rain.'}, {'pattern': 'abandon somebody', 'text': 'The country abandoned its political leaders after the war.'}, {'pattern': 'abandon somebody', 'text': 'The country abandoned its political leaders after the war.'}, {'pattern': 'abandon something', 'text': 'By 1930 he had abandoned his Marxist principles.'}]\n"
     ]
    }
   ],
   "source": [
    "print(new_data['abandon'])\n",
    "print(verb_data['abandon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f307177-6974-4f9c-a689-320cc549c865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3663"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(verb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6454c9ea-2750-4994-a574-af92c6c9b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(new_data, f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c55fa1f-af43-4523-8be7-739f62ebf46c",
   "metadata": {},
   "source": [
    "### 改成dataset形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d8574a9-46e3-4168-b361-83a59b4863b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d782d54-5849-49e5-a31b-ef767aae00e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('data.jsonlines','w') as f:\n",
    "    for i in data:\n",
    "        for j in data[i]:\n",
    "            f.write(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c066f00c-3f55-4c68-90ff-6996d493d14b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data.jsonlines\",\"r\") as f:\n",
    "    temp = set(f.readlines())\n",
    "with open(\"data1.jsonlines\",\"w\") as w:\n",
    "    for i in temp:\n",
    "        w.write(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482e8501-e616-41ef-8e25-4d4fbac777a0",
   "metadata": {},
   "source": [
    "### import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc5a086-4766-4f57-a874-4a273ba08341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0222470760345459,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating train split",
       "rate": null,
       "total": 0,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f38f9dfa6084944ad0daca965fc0bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = load_dataset(\"json\", data_files=\"data1.jsonlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "602b2f20-a563-4dcc-85c9-20dd18a56346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['pattern', 'text'],\n",
       "        num_rows: 8062\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d28a5-9a8d-432a-be1e-edcb264badd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81e8d4d-4a23-4fec-9629-37334b725f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_train_test = datasets[\"train\"].train_test_split(test_size=500)\n",
    "datasets_train_validation = datasets_train_test[\"train\"].train_test_split(test_size=500)\n",
    "\n",
    "datasets[\"train\"] = datasets_train_validation[\"train\"]\n",
    "datasets[\"validation\"] = datasets_train_validation[\"test\"]\n",
    "datasets[\"test\"] = datasets_train_test[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf336ed-deb8-4ac0-be17-136ccb1d33ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/nlplab/maggie/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb5b0c05-1396-4b0a-9bbc-271b6afb2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "max_input_length = 256\n",
    "max_target_length = 64\n",
    "\n",
    "def preprocess_data(examples):\n",
    "    inputs = [prefix + text for text in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"pattern\"], max_length=max_target_length, \n",
    "                       truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d6052e9-047d-4768-9c92-04fdbbd47e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.025195598602294922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 7062,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed5c2a2f340429086bc75169f4e0474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7062 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.027696847915649414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 500,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6bf587880e44a483f133f5c3ae3c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.026403188705444336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 500,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121d2fca2a2a4386a4de9c9127673a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e92114e3-ac06-47db-8221-97bd3f665d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['pattern', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 7062\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['pattern', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['pattern', 'text', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5451ba92-5917-42af-9c0b-aa4372f79f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94af0a3e-1ed5-4bf5-86c3-6e04d45b8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "model_name = \"t5-base-medium-title-generation\"\n",
    "model_dir = f\"t5_small\"\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    model_dir,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    learning_rate=4e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rouge1\",\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eae64d2e-bdcc-4dca-ac62-4c707fa54512",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afe0b82d-79ca-4a3e-8cc7-7be1601527a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-7154407f1f07>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"rouge\")\n",
      "/home/nlplab/maggie/.local/lib/python3.8/site-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a36b7468-74cb-406c-be9b-24044b072de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip()))\n",
    "                      for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) \n",
    "                      for label in decoded_labels]\n",
    "    \n",
    "    # Compute ROUGE scores\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels,\n",
    "                            use_stemmer=True)\n",
    "\n",
    "    # Extract ROUGE f1 scores\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length to metrics\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id)\n",
    "                      for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "362a13b1-28b3-4fbc-b4f3-50c68cb38f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlplab/maggie/.local/lib/python3.8/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Function that returns an untrained model to be trained\n",
    "def model_init():\n",
    "    return AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0139886-aaea-4375-b35b-42259e0318c1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "Traceback (most recent call last):\n",
       "  File \"/home/nlplab/maggie/.local/bin/tensorboard\", line 5, in <module>\n",
       "    from tensorboard.main import run_main\n",
       "  File \"/usr/local/lib/python3.8/dist-packages/tensorboard/main.py\", line 27, in <module>\n",
       "    from tensorboard import default\n",
       "  File \"/usr/local/lib/python3.8/dist-packages/tensorboard/default.py\", line 32, in <module>\n",
       "    from tensorboard.plugins.audio import audio_plugin\n",
       "  File \"/usr/local/lib/python3.8/dist-packages/tensorboard/plugins/audio/audio_plugin.py\", line 25, in <module>\n",
       "    from tensorboard.data import provider\n",
       "  File \"/usr/local/lib/python3.8/dist-packages/tensorboard/data/__init__.py\", line 17, in <module>\n",
       "    from tensorboard.data import experimental  # noqa: F401\n",
       "  File \"/usr/local/lib/python3.8/dist-packages/tensorboard/data/experimental/__init__.py\", line 17, in <module>\n",
       "    from tensorboard.data.experimental.experiment_from_dev import (  # noqa: F401\n",
       "  File \"/usr/local/lib/python3.8/dist-packages/tensorboard/data/experimental/experiment_from_dev.py\", line 25, in <module>\n",
       "    from tensorboard.uploader import auth\n",
       "  File \"/usr/local/lib/python3.8/dist-packages/tensorboard/uploader/auth.py\", line 28, in <module>\n",
       "    import google_auth_oauthlib.flow as auth_flows\n",
       "  File \"/usr/local/lib/python3.8/dist-packages/google_auth_oauthlib/__init__.py\", line 21, in <module>\n",
       "    from .interactive import get_user_credentials\n",
       "  File \"/usr/local/lib/python3.8/dist-packages/google_auth_oauthlib/interactive.py\", line 27, in <module>\n",
       "    import google_auth_oauthlib.flow\n",
       "  File \"/usr/local/lib/python3.8/dist-packages/google_auth_oauthlib/flow.py\", line 68, in <module>\n",
       "    import google_auth_oauthlib.helpers\n",
       "  File \"/usr/local/lib/python3.8/dist-packages/google_auth_oauthlib/helpers.py\", line 27, in <module>\n",
       "    from google.auth import external_account_authorized_user\n",
       "ImportError: cannot import name 'external_account_authorized_user' from 'google.auth' (/usr/local/lib/python3.8/dist-packages/google/auth/__init__.py)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start TensorBoard before training to monitor it in progress\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 't5_small'/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b96e2bfd-dbd7-48c5-9eba-bdfc5cf6fd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='883' max='883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [883/883 01:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.410400</td>\n",
       "      <td>2.491439</td>\n",
       "      <td>40.063300</td>\n",
       "      <td>10.664800</td>\n",
       "      <td>40.050300</td>\n",
       "      <td>39.964700</td>\n",
       "      <td>6.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.468600</td>\n",
       "      <td>1.736236</td>\n",
       "      <td>63.180500</td>\n",
       "      <td>30.629500</td>\n",
       "      <td>62.965400</td>\n",
       "      <td>62.934300</td>\n",
       "      <td>4.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.940600</td>\n",
       "      <td>1.485804</td>\n",
       "      <td>66.458400</td>\n",
       "      <td>34.663400</td>\n",
       "      <td>66.294500</td>\n",
       "      <td>66.264100</td>\n",
       "      <td>4.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.729000</td>\n",
       "      <td>1.340472</td>\n",
       "      <td>68.060200</td>\n",
       "      <td>36.064600</td>\n",
       "      <td>67.833500</td>\n",
       "      <td>67.761500</td>\n",
       "      <td>4.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.541800</td>\n",
       "      <td>1.254006</td>\n",
       "      <td>69.970000</td>\n",
       "      <td>37.851700</td>\n",
       "      <td>69.906300</td>\n",
       "      <td>69.820100</td>\n",
       "      <td>4.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.476400</td>\n",
       "      <td>1.211502</td>\n",
       "      <td>70.971300</td>\n",
       "      <td>39.628100</td>\n",
       "      <td>70.928000</td>\n",
       "      <td>70.932200</td>\n",
       "      <td>4.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.488300</td>\n",
       "      <td>1.173860</td>\n",
       "      <td>71.463800</td>\n",
       "      <td>40.442900</td>\n",
       "      <td>71.389400</td>\n",
       "      <td>71.370400</td>\n",
       "      <td>4.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.413200</td>\n",
       "      <td>1.163990</td>\n",
       "      <td>71.340600</td>\n",
       "      <td>40.258900</td>\n",
       "      <td>71.301700</td>\n",
       "      <td>71.305400</td>\n",
       "      <td>4.326000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=883, training_loss=2.0008316904070154, metrics={'train_runtime': 108.8386, 'train_samples_per_second': 64.885, 'train_steps_per_second': 8.113, 'total_flos': 24558721499136.0, 'train_loss': 2.0008316904070154, 'epoch': 1.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8c3ebb9-c5d6-4db4-b08a-89195786fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('gen3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c155cccb-c905-4721-9b8f-697536357430",
   "metadata": {},
   "source": [
    "### Try the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faf4cdff-42bb-4cf1-842b-fab50e5b0dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"t5-base-medium-title-generation/checkpoint-2000\"\n",
    "model_dir = f\"gen3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "\n",
    "max_input_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d6e5e2d-4439-4947-ae3a-34ce0772a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(text):\n",
    "    inputs = [\"summarize: \" + text]\n",
    "    inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=2, max_length=64)\n",
    "    decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    predicted = nltk.sent_tokenize(decoded_output.strip())[0]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08888cad-6549-4015-b21d-3cf727e207f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'available to somebody/something'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Not all the facts are made available\"\n",
    "\n",
    "gen(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b72d05-c7d6-4123-b44e-4909c7ea40d1",
   "metadata": {},
   "source": [
    "### Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a3f7292-f6cd-4d3e-b692-9ec0d48cfbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b786fddd3f8c46c6bf6ead0ed6e61a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 48.4733,\n",
       " 'rouge2': 4.4467,\n",
       " 'rougeL': 48.4381,\n",
       " 'rougeLsum': 48.3791,\n",
       " 'gen_len': 2.392}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# get test split\n",
    "test_tokenized_dataset = tokenized_datasets[\"test\"]\n",
    "\n",
    "# pad texts to the same length\n",
    "def preprocess_test(examples):\n",
    "    inputs = [prefix + text for text in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,\n",
    "                           padding=\"max_length\")\n",
    "    return model_inputs\n",
    "\n",
    "test_tokenized_dataset = test_tokenized_dataset.map(preprocess_test, batched=True)\n",
    "\n",
    "# prepare dataloader\n",
    "test_tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "dataloader = torch.utils.data.DataLoader(test_tokenized_dataset, batch_size=32)\n",
    "\n",
    "# generate text for each batch\n",
    "all_predictions = []\n",
    "for i,batch in enumerate(dataloader):\n",
    "    predictions = model.generate(**batch)\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "# flatten predictions\n",
    "all_predictions_flattened = [pred for preds in all_predictions for pred in preds]\n",
    "\n",
    "# tokenize and pad titles\n",
    "all_titles = tokenizer(test_tokenized_dataset[\"pattern\"], max_length=max_target_length,\n",
    "                       truncation=True, padding=\"max_length\")[\"input_ids\"]\n",
    "\n",
    "# compute metrics\n",
    "predictions_labels = [all_predictions_flattened, all_titles]\n",
    "compute_metrics(predictions_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad8698f2-553d-4c8a-9c8f-1fb532c873ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01747298240661621,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 500,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91515cb1c2e498c92781298be663961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 64.9055,\n",
       " 'rouge2': 47.6276,\n",
       " 'rougeL': 64.6296,\n",
       " 'rougeLsum': 64.5236,\n",
       " 'gen_len': 4.62}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# get test split\n",
    "test_tokenized_dataset = tokenized_datasets[\"test\"]\n",
    "\n",
    "# pad texts to the same length\n",
    "def preprocess_test(examples):\n",
    "    inputs = [prefix + text for text in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,\n",
    "                           padding=\"max_length\")\n",
    "    return model_inputs\n",
    "\n",
    "test_tokenized_dataset = test_tokenized_dataset.map(preprocess_test, batched=True)\n",
    "\n",
    "# prepare dataloader\n",
    "test_tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "dataloader = torch.utils.data.DataLoader(test_tokenized_dataset, batch_size=64)\n",
    "\n",
    "# generate text for each batch\n",
    "all_predictions = []\n",
    "for i,batch in enumerate(dataloader):\n",
    "    predictions = model.generate(**batch)\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "# flatten predictions\n",
    "all_predictions_flattened = [pred for preds in all_predictions for pred in preds]\n",
    "\n",
    "# tokenize and pad titles\n",
    "all_titles = tokenizer(test_tokenized_dataset[\"pattern\"], max_length=max_target_length,\n",
    "                       truncation=True, padding=\"max_length\")[\"input_ids\"]\n",
    "\n",
    "# compute metrics\n",
    "predictions_labels = [all_predictions_flattened, all_titles]\n",
    "compute_metrics(predictions_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
